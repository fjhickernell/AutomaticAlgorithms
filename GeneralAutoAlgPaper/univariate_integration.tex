
\newcommand{\R}{\mathbb{R}}
In the following cases, we focus on approximation of upper bound errors. Define Sobolev space:
\begin{align*}
  \mathcal{W}^{k,p}[0,1]=\{f\in C[0,1]: \|f^{k}\|_{p}<\infty\}.
\end{align*}
The input functions are in two specific ones:
\begin{align*}
  \cf=\mathcal{W}^{2,1} \text{ and }
  \cg=\mathcal{W}^{1,1},
\end{align*}
which has the semi-norm $\|f\|_{\cf}=\|f''\|_{1}$ and $\|f\|_{\cg}=\|f'\|_{1}$ respectively. The space of outputs $\ch$ is the real space $\R$. Given $\tau > 0$, we have the cone $\cc_{\tau} \subset \cf$ defined as
\begin{align}\label{coneinteg}
\cc_{\tau}=\{f\in \mathcal{W}^{2,1}:\|f''\|_1\leq\tau\|f'\|_1\}.
\end{align}

To approximate the integrations of functions in the cone based on the function values, define the solution operator $S$ as $S(f)=\int_{0}^{1}f(x)dx$. The goal is to make the error small, i.e. to find an algorithm A, for which $|\int_{0}^{1}f(x)dx-A(f)|\leq \varepsilon$.

We use the trapezoidal rule to approximate the integral. Consider a sequence of algorithms $\{A_n\}_{n\in \mathcal{I}}$, where $\mathcal{I}=\{2,3,\cdots\}$ with cost$(A_n)=n$, given the data $f(x_i)$, where $x_i=(i-1)/(n-1), i=1,\cdots,n$ are uniformly distributed between $[0,1]$ with corresponding function values, define $A_n(f)$ as: \begin{align*}
    A_{n}(f)
    =\frac{1}{2n}[f(x_1)+2f(x_2)+\cdots+2f(x_{n-1})+f(x_n)].
\end{align*}
According to (7.14) and (7.15) from \cite{BraPet11a}, the upper bound error function can be expressed as $\tilde{h}(n)=1/[2(n-1)]$, $h(n)=1/[8(n-1)^2]$.

\subsection{Upper Bounds}
 Fix the algorithm, trapezoidal rule, $A_n$, with cost$(A_n)=n$. One may estimate $\|f'\|_1$ in the following way:
 \begin{align}\label{1direst}
    G_n(f)=\sum_{i=0}^{n-1}\left|f(x_{i+1})-f(x_{i})\right|.
 \end{align} Note that $G_{n}(f)$ never overestimates $\|f'\|_{1}$, so $h_{\cg_{-}}(n)=0$. Consider \eqref{twosidedGineq}, in this case, the deflation factor, $\mathfrak{c}_n=1$. When it comes to the inflation factor, $\mathfrak{C}_n$, we consider that in the interval $(x_I,x_{x+1})$, we define the function $v(t,x)$ as
 \begin{align*}
   v(t,x)=\begin{cases}  \displaystyle  x_i-t, & x_i\leq t\leq x,\\[2ex]
 \displaystyle  t-x_{i+1}, & x< t \leq x_{i+1}.
\end{cases}
 \end{align*}
 Also that
 \begin{align*}
   \int_{x_i}^{x_{i+1}}|v(t,x)|dx=&\int_{x_i}^{t}|t-x_{i+1}|dx+\int_{t}^{x_{i+1}}|x_i-t|dx,\\
   =&(t-x_i)|t-x_{i+1}|+(x_{i+1}-t)|x_i-t|,\\
   =&2(t-x_i)(x_{i+1}-t).
 \end{align*}
 So,
 \begin{align*}
   f'(x)=&[f(x_{x+1})-f(x_{i})]+\int_{x_i}^{x_{i+1}}v(t,x)f''(t)dt,\\
   \Rightarrow \int_{x_i}^{x_{i+1}}|f'(x)|dx \leq & |f(x_{i+1})-f(x_i)|+\int_{x_i}^{x_{i+1}}\int_{x_i}^{x_{i+1}}|v(t,x)||f''(t)|dtdx,\\
   \leq & |f(x_{i+1})-f(x_i)|+\int_{x_i}^{x_{i+1}}2(t-x_i)(x_{i+1}-t)|f''(t)|dt,\\
   \leq & |f(x_{i+1})-f(x_i)|+\|2(t-x_i)(x_{i+1}-t)\|_{\infty}\|f''(t)\|_{1},\\
   \leq & |f(x_{i+1})-f(x_i)|+\frac{(x_{i+1}-x_{i})^2}{2}\|f''(t)\|_{1},\\
   \leq & |f(x_{i+1})-f(x_i)|+\frac{1}{2(n-1)^2}\|f''(t)\|_{1}.\\
 \end{align*}
 Consider the interval $(0,1)$:
 \begin{align*}
   &\int_{0}^{1}|f'(x)|dx,\\
   =&\sum_{i=1}^{n-1}\int_{x_i}^{x_{i+1}}|f'(x)|dx,\\
   \leq & \sum_{i=1}^{n-1}[f(x_{x+1})-f(x_{i})]+\sum_{i=1}^{n-1}\frac{1}{2(n-1)^2}\|f''(t)\|_{1},\\
   \leq & G_n(f)+\frac{1}{2(n-1)}\|f''(t)\|_{1}.\\
 \end{align*}
According to \eqref{Gerrbds}, we have $h_{+}(n)=\frac{1}{2(n-1)}$. So the deflation factor and inflation factor are as follows:
\begin{gather}\label{factor}
\mathfrak{c}_n =1 \\
\mathfrak{C}_n =\frac{1}{1 - \tau/(2(n-1))} \geq 1.
\end{gather}

It is trivial to find that if $h(n) \leq \tilde{h}(n) h_{+}(n), \forall n \in \mathcal{I},$ then $ \tau h(n)< \tilde{h}(n) \ \forall n \in \mathcal{I}.$
Thus we only need to find $n$ such that
\[
\frac{\tau \fC_n G_{n}(f)}{8(n-1)^2} \le \varepsilon.
\]
 
If we consider the embedded algorithms, we will have the following:
\begin{algo} \label{multistageintegalgo}
 Let the error tolerance $\varepsilon$, the maximum cost budget $N_{\text{max}}$ and the cone constant $\tau$ be given inputs. Let the sequence of algorithms $\{A_n\}_{n\in \mathcal{I}}$, $\{G_n\}_{n\in \mathcal{I}}$ be described above. Set $i=1$. Let $n_1=\lceil(\tau+1)/2\rceil+1$. For any input function $f\in\cf$, do the following:
\begin{description}
\item[Stage 1.\ Estimate {$\|f'\|_{1}$}.] First compute $G_{n_i}(f)$ in \eqref{1direst} and $\fC_n$ in \eqref{factor}.

\item[Stage 2. Check for convergence.] Check whether $n_i$ is large enough to satisfy the error tolerance, i.e.
    \begin{align*}
      \frac{\tau \fC_{n_i} G_{n_i}(f)}{8(n_i-1)^2} \le \varepsilon.
    \end{align*}
    If this is true, then set $W=0$, return $(A_{n_i}(f),W)$ and terminate the algorithm. If this is not true, go to Stage 3.

\item[Stage 3. Compute $n_{i+1}$.] Choose $n_{i+1}$ as the smallest number exceeding $n_i$ and not less than $N_A(\varepsilon/G_{n_i}(f))$ such that $A_n$ is embedded in $A_{n+1}$. That is
    \begin{align*}
      n_{i+1}=(n_i-1)\left\lceil\frac{1}{n_{i}-1}\sqrt{\frac{\tau G_{n_i}(f)}{8\varepsilon}}\right\rceil+1.
    \end{align*}
    If $n_{i+1}\leq N{\text{max}}$, increment $i$ by 1, and return to Stage 1. Otherwise, if $n_{i+1}> N{\text{max}}$, choose $n_{i+1}$ be the largest number not exceeding $N{\text{max}}$ such that $A_n$ is embedded in $A_{n+1}$ and set $W=1$. Return $(A_{n_{i+1}}(f),W)$ and terminate the algorithm.
\end{description}
\end{algo}

 \begin{theorem}

Let  $\varepsilon$, $N_{\max}$, $\tau$ and $n_1$ be given as described in Algorithm \ref{multistageintegalgo}.
Assume that $n_1 \le N_{\max}$. Let $r$ be the number described in the paragraph preceding that algorithm.
Let $\cc_\tau$ be the cone of functions defined in \eqref{coneinteg}.
Define
\[
\tN_A(a) = \min\left\{ n \in \ci : \frac{\tau \fC_n }{8(n-1)^2} \le a \right\}, \quad a \in (0,\infty).
\]
and
$$
\cn = \left \{ f \in \cc_\tau :r\tN_{A}\left(\frac{\varepsilon}{\sigma} \right) \le N_{\max} \right\}
= \left \{ f \in \cc_\tau : \sigma \le \frac{8(N_{\max}/r-1)^2 \varepsilon }{\tau \fC_{N_{\max}/r}  } \right\}
$$
be the nice subset of the cone $\cc_\tau$.  Then it follows that Algorithm \ref{multistageintegalgo} is successful for all functions in $\cn$,  i.e.,  $\success(A,W,\cn,\varepsilon,N_{\max}) = 1$.  Moreover, the cost of this algorithm is bounded above in terms of the $\|f'\|_{1}$ of the input function as follows:
\begin{multline}
\cost(A,\cn,\varepsilon,N_{\max},\sigma) \\
\le  \min\left\{ n \in \ci : n \ge \left(\frac{\sigma\tau}{8\varepsilon(1 - \tau/(2(n_{1}-1)))}\right)^{\frac{1}{2}} +1\right\}
\end{multline} where $\sigma=\|f'\|_{1}.$
 \end{theorem}

\begin{proof}
Applied Theorem \ref{MultiStageThm}, then we can have the above result.
\end{proof}




\subsection{Lower Bounds}
Now we consider the lower bound. We define the fooling function as $f_{\pm}=c_0f_0\pm c_1f_1$. The first piece of the fooling function is defined by $f_0=x$. In this case,
\begin{align*}
    \|f_0\|_{W^{1,1}}&=\|f'_0\|_1=1,\\
    \|f_0\|_{W^{2,1}}&=\|f''_0\|_1=0=\tau_0.
\end{align*}

The second part depends on the sample points. Given any $n$ sample points $\{\xi_i\}_{i=1}^{n}$ between $0$ and $1$ such that $0=\xi_0\leq \xi_1<\cdots<\xi_n\leq \xi_{n+1}=1$, let $l$ and $u$ be the two consecutive points with maximum distance between them, i.e. $\exists j\in \{1,2,\cdots,n-1\}$ such that $l=\xi_j, u=\xi_{j+1}$ and $u-l=\max_{1\leq i\leq n}(\xi_{i+1}-\xi_i)$. Then let
$$f_1(x)=\begin{cases}  \displaystyle  \frac{30(x-l^2)(x-u)^2}{(u-l)^5}, & l\leq x\leq u,\\[2ex]
 \displaystyle  0, & \text{otherwise}.
\end{cases}.$$
Note that
\begin{align*}
    \|S(f_1)\|_{W^{1,1}}&=\int_{0}^{1}f_1(x)dx=1,\\
    \|f_1\|_{W^{1,1}}&=\|f'_{1}\|_1=\frac{15}{4(u-l)}\leq \frac{15}{4}(n+1)=g(n),\\
    \|f_1\|_{W^{2,1}}&=\|f''_{1}\|_1=\frac{40}{\sqrt{3}(u-l)^2}=\frac{32}{3\sqrt{3}(u-l)}\|f_1'\|_1\leq \frac{32}{3\sqrt{3}}(n+1)\|f_1'\|_1%=\tilde{g}(n)g(n).
\end{align*}
We can easily get that $g^{-1}(n)=\frac{4}{15}x-1$ and $(\tilde{g}g)^{-1}(x)=\sqrt{\frac{\sqrt{3}}{40}x}-1$. So according to Theorem \ref{MultiStageThm} in the paper, $$\text{comp}\geq \min\left(\frac{4}{15}(\frac{\sigma}{4\varepsilon})+1,\sqrt{\frac{\sqrt{3}}{40}\frac{\sigma\tau}{4\varepsilon}}+1\right)=\min\left(\frac{\sigma}{15\varepsilon},\sqrt{\frac{\sqrt{3}\sigma\tau}{160\varepsilon}}\right)+1$$


\begin{theorem} \label{complowbdinteg} Suppose that functions $f_{0}$ and $f_1$ can be found that satisfy conditions \eqref{assumpfone} and \eqref{assumpfzero}.  It then follows that the complexity of the problem, defined by \eqref{complexdef}, assuming infinite cost budget, over the cone of functions $\cc_{\tau}$ is
$$
\comp(\varepsilon,\ca(\cc_{\tau},\ch,S,\Lambda),\infty,\sigma)
\ge \min\left(\frac{\sigma}{15\varepsilon},\sqrt{\frac{\sqrt{3}\sigma\tau}{160\varepsilon}}\right)+1.
$$
\end{theorem}

\begin{proof}
$g(n), \ \tg(n)$ and $\tau_0$ is obtained above, then by Theorem \ref{complowbd}
we can have the above results.
\end{proof}

\subsection{Numerical Example}
Consider the test function $f(x)=e^{-(a(x-\mu))^2},$
where $\mu$'s are uniformly distributed on $[-1/\sqrt{2}a,1-1/\sqrt{2}a],$ and $\log_{10} a \sim U[0,4].$
If we have large $a$, we can hardly approximate the function due to the spiky shape of the function. From the numerical results, we can find the success rate for our algorithm. Since $\norm[1]{f'}=-e^{-(a\mu)^2}-e^{-(a(1-\mu))^2}, \ \norm[1]{f''}=-2a(\mu e^{-(a\mu)^2}+(1-\mu)e^{-(a(1-\mu))^2})$, if $f \in \cc_{\tau}$ then we should have
$\norm[1]{f''}/\norm[1]{f'} \leq \tau$. We use Monte Carlo simulation with 1000000 samples to estimate this probability. To obtain the observed success rate, here we use $\tau = 10, 25 , 100$ separately to test $10000$ times with $\varepsilon = 1e-7$.
\begin{table}[h]
\centering
\begin{tabular}{cccc}
$\tau$ &  10 & 25 & 100\\
\toprule
Probability of $f \in \mathfrak{C}_{\tau}$ &  $\leq 45 \%$ &  $\leq 50 \%$  & $\leq 54 \%$ \\
Observed Success Rate & $52\%$ &  $60\%$  & $74\%$ \\
\end{tabular}
\caption{ Comparison between probability of the input function lying in the cone and the empirical success rate of the algorithm}
\end{table}

From the above table, we can find our algorithm works very well, as the observed
success rate is always larger than the expected success rate.
